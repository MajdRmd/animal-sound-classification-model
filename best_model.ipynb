{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "A-aUO6ZqIQM2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.image import resize\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCBQVY5QIXG-",
        "outputId": "31ace3c3-12bd-4a4a-961a-d659d0d91c54"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import (Input, Conv2D, MaxPooling2D, Dropout, Dense,\n",
        "                                     BatchNormalization, Flatten, GlobalAveragePooling2D)\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage.transform import resize\n",
        "\n",
        "# Define your folder structure\n",
        "data_dir = '/content/drive/MyDrive/training_dataset'\n",
        "classes = ['cat', 'dog','bird','cow','lion','sheep','frog','chicken','donkey','monkey', 'others']\n",
        "\n",
        "# Load and preprocess audio data\n",
        "def load_and_preprocess_data(data_dir, classes, target_shape=(128, 128)):\n",
        "    data = []\n",
        "    labels = []\n",
        "\n",
        "    for i, class_name in enumerate(classes):\n",
        "        class_dir = os.path.join(data_dir, class_name)\n",
        "        if os.path.exists(class_dir):\n",
        "            for filename in os.listdir(class_dir):\n",
        "                if filename.endswith('.wav'):\n",
        "                    file_path = os.path.join(class_dir, filename)\n",
        "                    audio_data, sample_rate = librosa.load(file_path, sr=22050)\n",
        "\n",
        "                    # Convert to Mel spectrogram\n",
        "                    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate, n_mels=128)\n",
        "                    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)  # Convert to dB scale\n",
        "\n",
        "                    # Resize for CNN input\n",
        "                    mel_spectrogram = resize(mel_spectrogram, target_shape, mode='constant')\n",
        "                    mel_spectrogram = np.expand_dims(mel_spectrogram, axis=-1)  # Add channel dimension\n",
        "\n",
        "                    data.append(mel_spectrogram)\n",
        "                    labels.append(i)\n",
        "\n",
        "    return np.array(data), np.array(labels)\n",
        "\n",
        "# Data Augmentation (Time Shift, Noise Injection, Pitch Shift)\n",
        "def augment_audio(audio, sr):\n",
        "    if np.random.rand() < 0.3:\n",
        "        audio = np.roll(audio, shift=int(sr * 0.1))  # Time Shift\n",
        "    if np.random.rand() < 0.3:\n",
        "        audio += 0.005 * np.random.randn(len(audio))  # Add Gaussian Noise\n",
        "    if np.random.rand() < 0.3:\n",
        "        audio = librosa.effects.pitch_shift(audio, sr=sr, n_steps=np.random.uniform(-2, 2))  # Pitch Shift\n",
        "    return audio\n",
        "\n",
        "# Load and split data\n",
        "data, labels = load_and_preprocess_data(data_dir, classes)\n",
        "labels = to_categorical(labels, num_classes=len(classes))\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define CNN model\n",
        "input_shape = X_train.shape[1:]\n",
        "\n",
        "input_layer = Input(shape=input_shape)\n",
        "\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_layer)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.4)(x)\n",
        "\n",
        "x = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "x = GlobalAveragePooling2D()(x)  # Prevents overfitting by reducing parameter count\n",
        "\n",
        "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "\n",
        "output_layer = Dense(len(classes), activation='softmax')(x)\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "\n",
        "# Compile the model\n",
        "optimizer = Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', mode='max')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=32,\n",
        "                    callbacks=[early_stopping, reduce_lr, model_checkpoint])\n"
      ],
      "metadata": {
        "id": "OcEWRSnrIfSe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01cb5fc0-b388-4a5a-a207-d3b391540f8f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.2514 - loss: 7.1606"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 4s/step - accuracy: 0.2530 - loss: 7.1426 - val_accuracy: 0.1497 - val_loss: 16.7711 - learning_rate: 0.0010\n",
            "Epoch 2/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.4981 - loss: 4.9816"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.4988 - loss: 4.9739 - val_accuracy: 0.2177 - val_loss: 6.8810 - learning_rate: 0.0010\n",
            "Epoch 3/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6035 - loss: 3.8822"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.6037 - loss: 3.8758 - val_accuracy: 0.4558 - val_loss: 3.7956 - learning_rate: 0.0010\n",
            "Epoch 4/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.6983 - loss: 2.9668"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m209s\u001b[0m 5s/step - accuracy: 0.6979 - loss: 2.9643 - val_accuracy: 0.5068 - val_loss: 3.0585 - learning_rate: 0.0010\n",
            "Epoch 5/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m195s\u001b[0m 4s/step - accuracy: 0.7379 - loss: 2.3653 - val_accuracy: 0.3878 - val_loss: 2.9844 - learning_rate: 0.0010\n",
            "Epoch 6/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.7685 - loss: 1.9489"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.7691 - loss: 1.9459 - val_accuracy: 0.5510 - val_loss: 2.5039 - learning_rate: 0.0010\n",
            "Epoch 7/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8335 - loss: 1.5063"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 4s/step - accuracy: 0.8334 - loss: 1.5052 - val_accuracy: 0.5612 - val_loss: 2.2849 - learning_rate: 0.0010\n",
            "Epoch 8/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 4s/step - accuracy: 0.7994 - loss: 1.3696 - val_accuracy: 0.3844 - val_loss: 2.6283 - learning_rate: 0.0010\n",
            "Epoch 9/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 4s/step - accuracy: 0.8565 - loss: 1.0919 - val_accuracy: 0.2891 - val_loss: 4.8381 - learning_rate: 0.0010\n",
            "Epoch 10/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.8896 - loss: 0.9057"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.8896 - loss: 0.9048 - val_accuracy: 0.5816 - val_loss: 1.9041 - learning_rate: 0.0010\n",
            "Epoch 11/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9022 - loss: 0.7395"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9022 - loss: 0.7394 - val_accuracy: 0.6599 - val_loss: 1.6725 - learning_rate: 0.0010\n",
            "Epoch 12/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9058 - loss: 0.6620"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9057 - loss: 0.6626 - val_accuracy: 0.7211 - val_loss: 1.2031 - learning_rate: 0.0010\n",
            "Epoch 13/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9058 - loss: 0.6293 - val_accuracy: 0.3741 - val_loss: 3.9376 - learning_rate: 0.0010\n",
            "Epoch 14/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 4s/step - accuracy: 0.9284 - loss: 0.5529 - val_accuracy: 0.5408 - val_loss: 1.8373 - learning_rate: 0.0010\n",
            "Epoch 15/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 4s/step - accuracy: 0.9388 - loss: 0.4611 - val_accuracy: 0.5578 - val_loss: 1.8211 - learning_rate: 0.0010\n",
            "Epoch 16/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.9261 - loss: 0.4824 - val_accuracy: 0.2211 - val_loss: 4.6200 - learning_rate: 0.0010\n",
            "Epoch 17/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9549 - loss: 0.3832\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9549 - loss: 0.3831 - val_accuracy: 0.4456 - val_loss: 2.5359 - learning_rate: 0.0010\n",
            "Epoch 18/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9666 - loss: 0.3301"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.9666 - loss: 0.3300 - val_accuracy: 0.9218 - val_loss: 0.4704 - learning_rate: 5.0000e-04\n",
            "Epoch 19/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.9724 - loss: 0.3049 - val_accuracy: 0.8844 - val_loss: 0.5252 - learning_rate: 5.0000e-04\n",
            "Epoch 20/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9876 - loss: 0.2341 - val_accuracy: 0.8912 - val_loss: 0.5533 - learning_rate: 5.0000e-04\n",
            "Epoch 21/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.9841 - loss: 0.2328 - val_accuracy: 0.8810 - val_loss: 0.5098 - learning_rate: 5.0000e-04\n",
            "Epoch 22/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9875 - loss: 0.2077"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 4s/step - accuracy: 0.9876 - loss: 0.2076 - val_accuracy: 0.9252 - val_loss: 0.4401 - learning_rate: 5.0000e-04\n",
            "Epoch 23/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - accuracy: 0.9955 - loss: 0.1784 - val_accuracy: 0.8741 - val_loss: 0.6100 - learning_rate: 5.0000e-04\n",
            "Epoch 24/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9937 - loss: 0.1688"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9937 - loss: 0.1689 - val_accuracy: 0.9286 - val_loss: 0.3959 - learning_rate: 5.0000e-04\n",
            "Epoch 25/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m205s\u001b[0m 4s/step - accuracy: 0.9861 - loss: 0.1761 - val_accuracy: 0.8571 - val_loss: 0.5744 - learning_rate: 5.0000e-04\n",
            "Epoch 26/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.9892 - loss: 0.1742 - val_accuracy: 0.9048 - val_loss: 0.4734 - learning_rate: 5.0000e-04\n",
            "Epoch 27/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 4s/step - accuracy: 0.9954 - loss: 0.1544 - val_accuracy: 0.8639 - val_loss: 0.5601 - learning_rate: 5.0000e-04\n",
            "Epoch 28/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9916 - loss: 0.1531"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 4s/step - accuracy: 0.9916 - loss: 0.1530 - val_accuracy: 0.9558 - val_loss: 0.2984 - learning_rate: 5.0000e-04\n",
            "Epoch 29/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9908 - loss: 0.1425 - val_accuracy: 0.9218 - val_loss: 0.3501 - learning_rate: 5.0000e-04\n",
            "Epoch 30/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9834 - loss: 0.1447 - val_accuracy: 0.8776 - val_loss: 0.5761 - learning_rate: 5.0000e-04\n",
            "Epoch 31/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - accuracy: 0.9938 - loss: 0.1358 - val_accuracy: 0.4762 - val_loss: 2.4858 - learning_rate: 5.0000e-04\n",
            "Epoch 32/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m198s\u001b[0m 4s/step - accuracy: 0.9917 - loss: 0.1387 - val_accuracy: 0.7959 - val_loss: 0.7057 - learning_rate: 5.0000e-04\n",
            "Epoch 33/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9910 - loss: 0.1384\n",
            "Epoch 33: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 0.9910 - loss: 0.1384 - val_accuracy: 0.9286 - val_loss: 0.3270 - learning_rate: 5.0000e-04\n",
            "Epoch 34/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.9930 - loss: 0.1164 - val_accuracy: 0.9218 - val_loss: 0.3115 - learning_rate: 2.5000e-04\n",
            "Epoch 35/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m162s\u001b[0m 4s/step - accuracy: 0.9961 - loss: 0.1109 - val_accuracy: 0.9320 - val_loss: 0.3392 - learning_rate: 2.5000e-04\n",
            "Epoch 36/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9982 - loss: 0.1093 - val_accuracy: 0.9116 - val_loss: 0.3875 - learning_rate: 2.5000e-04\n",
            "Epoch 37/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9967 - loss: 0.1026 - val_accuracy: 0.9388 - val_loss: 0.2818 - learning_rate: 2.5000e-04\n",
            "Epoch 38/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9956 - loss: 0.0953 - val_accuracy: 0.8810 - val_loss: 0.4592 - learning_rate: 2.5000e-04\n",
            "Epoch 39/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9983 - loss: 0.0933 - val_accuracy: 0.9524 - val_loss: 0.2644 - learning_rate: 2.5000e-04\n",
            "Epoch 40/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - accuracy: 0.9993 - loss: 0.0880 - val_accuracy: 0.9286 - val_loss: 0.2833 - learning_rate: 2.5000e-04\n",
            "Epoch 41/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9973 - loss: 0.0834 - val_accuracy: 0.9422 - val_loss: 0.2625 - learning_rate: 2.5000e-04\n",
            "Epoch 42/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m202s\u001b[0m 4s/step - accuracy: 0.9997 - loss: 0.0836 - val_accuracy: 0.9422 - val_loss: 0.2656 - learning_rate: 2.5000e-04\n",
            "Epoch 43/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 4s/step - accuracy: 0.9977 - loss: 0.0876 - val_accuracy: 0.9422 - val_loss: 0.2983 - learning_rate: 2.5000e-04\n",
            "Epoch 44/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 4s/step - accuracy: 0.9995 - loss: 0.0810 - val_accuracy: 0.9456 - val_loss: 0.2634 - learning_rate: 2.5000e-04\n",
            "Epoch 45/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0796 - val_accuracy: 0.9320 - val_loss: 0.3195 - learning_rate: 2.5000e-04\n",
            "Epoch 46/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4s/step - accuracy: 0.9991 - loss: 0.0807\n",
            "Epoch 46: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m206s\u001b[0m 4s/step - accuracy: 0.9991 - loss: 0.0806 - val_accuracy: 0.9354 - val_loss: 0.3115 - learning_rate: 2.5000e-04\n",
            "Epoch 47/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m200s\u001b[0m 4s/step - accuracy: 0.9990 - loss: 0.0739 - val_accuracy: 0.9422 - val_loss: 0.2921 - learning_rate: 1.2500e-04\n",
            "Epoch 48/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m203s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0712 - val_accuracy: 0.9490 - val_loss: 0.2555 - learning_rate: 1.2500e-04\n",
            "Epoch 49/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 4s/step - accuracy: 0.9953 - loss: 0.0780 - val_accuracy: 0.9422 - val_loss: 0.2530 - learning_rate: 1.2500e-04\n",
            "Epoch 50/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m201s\u001b[0m 4s/step - accuracy: 0.9989 - loss: 0.0688 - val_accuracy: 0.9524 - val_loss: 0.2352 - learning_rate: 1.2500e-04\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def predict_with_others_class(model, X_test, threshold=0.5):\n",
        "    predictions = model.predict(X_test)\n",
        "    predicted_classes = np.argmax(predictions, axis=1)  # Get the index of the highest probability\n",
        "\n",
        "    # If the max probability is less than the threshold, classify as \"others\" (last class)\n",
        "    max_probs = np.max(predictions, axis=1)\n",
        "    others_class = len(classes) - 1  # \"others\" is the last class\n",
        "\n",
        "    for i in range(len(predicted_classes)):\n",
        "        if max_probs[i] < threshold:\n",
        "            predicted_classes[i] = others_class  # Assign \"others\" if probability is less than threshold\n",
        "\n",
        "    return predicted_classes\n"
      ],
      "metadata": {
        "id": "GzIgYBYfEB1O"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy=model.evaluate(X_test,y_test,verbose=0)\n",
        "print(test_accuracy[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl0IHrJP4PKx",
        "outputId": "d02e89c1-99ea-424b-d491-0ca89d0266fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7752442955970764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_accuracy',  # Monitor validation loss\n",
        "    patience=10,          # Number of epochs with no improvement before stopping\n",
        "    restore_best_weights=True # Restore model to best epoch\n",
        ")\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OHQCg3mtJfDe"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSxgFAq7JkM7",
        "outputId": "c65a3137-2dcd-45c8-81c0-c016df92fe23"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 845ms/step - accuracy: 0.3957 - loss: 8.0373 - val_accuracy: 0.4218 - val_loss: 1.9139\n",
            "Epoch 2/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 830ms/step - accuracy: 0.4008 - loss: 2.2176 - val_accuracy: 0.4524 - val_loss: 1.8587\n",
            "Epoch 3/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 829ms/step - accuracy: 0.5495 - loss: 1.5292 - val_accuracy: 0.5034 - val_loss: 1.7569\n",
            "Epoch 4/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 834ms/step - accuracy: 0.5718 - loss: 1.4154 - val_accuracy: 0.5238 - val_loss: 1.5769\n",
            "Epoch 5/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 829ms/step - accuracy: 0.6279 - loss: 1.2437 - val_accuracy: 0.5544 - val_loss: 1.4759\n",
            "Epoch 6/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 844ms/step - accuracy: 0.6642 - loss: 1.0845 - val_accuracy: 0.5850 - val_loss: 1.4106\n",
            "Epoch 7/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 835ms/step - accuracy: 0.6543 - loss: 1.1507 - val_accuracy: 0.6054 - val_loss: 1.3945\n",
            "Epoch 8/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 862ms/step - accuracy: 0.6931 - loss: 1.0438 - val_accuracy: 0.6463 - val_loss: 1.3217\n",
            "Epoch 9/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 859ms/step - accuracy: 0.7487 - loss: 0.8369 - val_accuracy: 0.6156 - val_loss: 1.3827\n",
            "Epoch 10/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 813ms/step - accuracy: 0.7413 - loss: 0.8916 - val_accuracy: 0.6395 - val_loss: 1.6117\n",
            "Epoch 11/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 836ms/step - accuracy: 0.7681 - loss: 0.8643 - val_accuracy: 0.6361 - val_loss: 1.3869\n",
            "Epoch 12/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 820ms/step - accuracy: 0.7654 - loss: 0.8031 - val_accuracy: 0.6531 - val_loss: 1.5461\n",
            "Epoch 13/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 834ms/step - accuracy: 0.7749 - loss: 0.7390 - val_accuracy: 0.6871 - val_loss: 1.6389\n",
            "Epoch 14/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 807ms/step - accuracy: 0.7835 - loss: 0.7922 - val_accuracy: 0.6837 - val_loss: 1.6477\n",
            "Epoch 15/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 823ms/step - accuracy: 0.8200 - loss: 0.6159 - val_accuracy: 0.6837 - val_loss: 1.5467\n",
            "Epoch 16/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 818ms/step - accuracy: 0.8345 - loss: 0.6024 - val_accuracy: 0.6973 - val_loss: 1.5390\n",
            "Epoch 17/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 793ms/step - accuracy: 0.8281 - loss: 0.5416 - val_accuracy: 0.6701 - val_loss: 1.5987\n",
            "Epoch 18/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 808ms/step - accuracy: 0.8127 - loss: 0.7604 - val_accuracy: 0.7007 - val_loss: 1.5475\n",
            "Epoch 19/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 819ms/step - accuracy: 0.8486 - loss: 0.5403 - val_accuracy: 0.7279 - val_loss: 1.6878\n",
            "Epoch 20/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 799ms/step - accuracy: 0.8344 - loss: 0.5243 - val_accuracy: 0.7075 - val_loss: 1.6699\n",
            "Epoch 21/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 822ms/step - accuracy: 0.8409 - loss: 0.5771 - val_accuracy: 0.7245 - val_loss: 1.5115\n",
            "Epoch 22/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 825ms/step - accuracy: 0.8550 - loss: 0.4588 - val_accuracy: 0.7483 - val_loss: 1.5449\n",
            "Epoch 23/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 830ms/step - accuracy: 0.8865 - loss: 0.4128 - val_accuracy: 0.7381 - val_loss: 1.7214\n",
            "Epoch 24/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 862ms/step - accuracy: 0.8661 - loss: 0.4941 - val_accuracy: 0.7449 - val_loss: 1.6262\n",
            "Epoch 25/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 805ms/step - accuracy: 0.8805 - loss: 0.4235 - val_accuracy: 0.7517 - val_loss: 1.8756\n",
            "Epoch 26/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 848ms/step - accuracy: 0.9170 - loss: 0.2744 - val_accuracy: 0.7381 - val_loss: 2.0735\n",
            "Epoch 27/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 817ms/step - accuracy: 0.8978 - loss: 0.3665 - val_accuracy: 0.7551 - val_loss: 1.9279\n",
            "Epoch 28/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 846ms/step - accuracy: 0.9083 - loss: 0.3150 - val_accuracy: 0.7483 - val_loss: 1.8222\n",
            "Epoch 29/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 846ms/step - accuracy: 0.8945 - loss: 0.4401 - val_accuracy: 0.7755 - val_loss: 2.3265\n",
            "Epoch 30/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 793ms/step - accuracy: 0.8928 - loss: 0.4285 - val_accuracy: 0.7517 - val_loss: 2.3282\n",
            "Epoch 31/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 820ms/step - accuracy: 0.8951 - loss: 0.4789 - val_accuracy: 0.7415 - val_loss: 2.1525\n",
            "Epoch 32/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 813ms/step - accuracy: 0.8934 - loss: 0.4280 - val_accuracy: 0.7551 - val_loss: 2.0967\n",
            "Epoch 33/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 851ms/step - accuracy: 0.9240 - loss: 0.2784 - val_accuracy: 0.7789 - val_loss: 2.0114\n",
            "Epoch 34/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 821ms/step - accuracy: 0.9303 - loss: 0.3090 - val_accuracy: 0.7891 - val_loss: 2.1309\n",
            "Epoch 35/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 823ms/step - accuracy: 0.9114 - loss: 0.2842 - val_accuracy: 0.7789 - val_loss: 2.2789\n",
            "Epoch 36/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 817ms/step - accuracy: 0.9243 - loss: 0.2622 - val_accuracy: 0.7687 - val_loss: 2.2797\n",
            "Epoch 37/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 844ms/step - accuracy: 0.9083 - loss: 0.2726 - val_accuracy: 0.7755 - val_loss: 2.2955\n",
            "Epoch 38/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 803ms/step - accuracy: 0.9237 - loss: 0.3095 - val_accuracy: 0.7823 - val_loss: 2.2266\n",
            "Epoch 39/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 846ms/step - accuracy: 0.9205 - loss: 0.3492 - val_accuracy: 0.7789 - val_loss: 2.3444\n",
            "Epoch 40/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 815ms/step - accuracy: 0.9225 - loss: 0.2922 - val_accuracy: 0.7789 - val_loss: 2.3020\n",
            "Epoch 41/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 842ms/step - accuracy: 0.9348 - loss: 0.2608 - val_accuracy: 0.7755 - val_loss: 2.1621\n",
            "Epoch 42/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 848ms/step - accuracy: 0.9390 - loss: 0.2424 - val_accuracy: 0.7993 - val_loss: 2.3452\n",
            "Epoch 43/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 801ms/step - accuracy: 0.9422 - loss: 0.1955 - val_accuracy: 0.7925 - val_loss: 2.2977\n",
            "Epoch 44/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 812ms/step - accuracy: 0.9302 - loss: 0.2192 - val_accuracy: 0.7959 - val_loss: 2.7389\n",
            "Epoch 45/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 801ms/step - accuracy: 0.9348 - loss: 0.2928 - val_accuracy: 0.8027 - val_loss: 2.7233\n",
            "Epoch 46/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 859ms/step - accuracy: 0.9416 - loss: 0.3523 - val_accuracy: 0.7687 - val_loss: 2.8127\n",
            "Epoch 47/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 856ms/step - accuracy: 0.9443 - loss: 0.1951 - val_accuracy: 0.8095 - val_loss: 2.5281\n",
            "Epoch 48/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 803ms/step - accuracy: 0.9556 - loss: 0.2186 - val_accuracy: 0.7993 - val_loss: 2.2190\n",
            "Epoch 49/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 818ms/step - accuracy: 0.9263 - loss: 0.3101 - val_accuracy: 0.7891 - val_loss: 2.0447\n",
            "Epoch 50/50\n",
            "\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 801ms/step - accuracy: 0.9329 - loss: 0.3085 - val_accuracy: 0.7721 - val_loss: 2.3801\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ea0ac585450>"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('awid_model_others.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1B9G7vrK2jv",
        "outputId": "541c663b-36bb-41c5-b172-b545d782ed82"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('best_model.h5')\n",
        "\n",
        "# Define the target shape for input spectrograms\n",
        "target_shape = (128, 128)\n",
        "\n",
        "# Define your class labels\n",
        "classes = ['cat', 'dog','bird','cow','lion','sheep','frog','chicken','donkey','monkey','others']\n",
        "\n",
        "# Function to preprocess and classify an audio file\n",
        "def test_audio(file_path, model):\n",
        "    # Load and preprocess the audio file\n",
        "    audio_data, sample_rate = librosa.load(file_path, sr=16000)\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sample_rate)\n",
        "    mel_spectrogram = resize(np.expand_dims(mel_spectrogram, axis=-1), target_shape)\n",
        "    mel_spectrogram = tf.reshape(mel_spectrogram, (1,) + target_shape + (1,))\n",
        "\n",
        "    # Make predictions\n",
        "    predictions = model.predict(mel_spectrogram)\n",
        "\n",
        "    # Get the class probabilities\n",
        "    class_probabilities = predictions[0]\n",
        "\n",
        "    # Get the predicted class index\n",
        "    predicted_class_index = np.argmax(class_probabilities)\n",
        "\n",
        "    return class_probabilities, predicted_class_index\n",
        "\n",
        "# Test an audio file\n",
        "test_audio_file = 'cow.wav'\n",
        "class_probabilities, predicted_class_index = test_audio(test_audio_file, model)\n",
        "\n",
        "# Display results for all classes\n",
        "for i, class_label in enumerate(classes):\n",
        "    probability = class_probabilities[i]\n",
        "    print(f'Class: {class_label}, Probability: {probability:.4f}')\n",
        "\n",
        "# Calculate and display the predicted class and accuracy\n",
        "predicted_class = classes[predicted_class_index]\n",
        "accuracy = class_probabilities[predicted_class_index]\n",
        "print(f'The audio is classified as: {predicted_class}')\n",
        "print(f'Accuracy: {accuracy:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "reCtnDo4K_QK",
        "outputId": "9a688840-2ab1-4476-cdc6-62842b8f792d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 227ms/step\n",
            "Class: cat, Probability: 0.0000\n",
            "Class: dog, Probability: 0.0000\n",
            "Class: bird, Probability: 0.0000\n",
            "Class: cow, Probability: 0.0000\n",
            "Class: lion, Probability: 0.0000\n",
            "Class: sheep, Probability: 0.0000\n",
            "Class: frog, Probability: 1.0000\n",
            "Class: chicken, Probability: 0.0000\n",
            "Class: donkey, Probability: 0.0000\n",
            "Class: monkey, Probability: 0.0000\n",
            "Class: others, Probability: 0.0000\n",
            "The audio is classified as: frog\n",
            "Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "import os\n",
        "from skimage.transform import resize\n",
        "import tensorflow as tf\n",
        "\n",
        "# Define classes\n",
        "classes = ['cat', 'dog', 'bird', 'cow', 'lion', 'sheep', 'frog', 'chicken', 'donkey', 'monkey', 'others']\n",
        "\n",
        "# Load trained model\n",
        "model = tf.keras.models.load_model('best_model.h5')  # Update with correct path\n",
        "\n",
        "def preprocess_audio(file_path, target_shape=(128, 128)):\n",
        "    audio_data, sr = librosa.load(file_path, sr=22050)\n",
        "\n",
        "    # Convert to Mel spectrogram\n",
        "    mel_spectrogram = librosa.feature.melspectrogram(y=audio_data, sr=sr, n_mels=128)\n",
        "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
        "\n",
        "    # Resize to match CNN input\n",
        "    mel_spectrogram = resize(mel_spectrogram, target_shape, mode='constant')\n",
        "    mel_spectrogram = np.expand_dims(mel_spectrogram, axis=-1)  # Keep only 1 channel\n",
        "\n",
        "    return np.expand_dims(mel_spectrogram, axis=0)  # Add batch dimension\n",
        "\n",
        "\n",
        "# Function to predict audio file class\n",
        "def predict_audio(file_path):\n",
        "    preprocessed_audio = preprocess_audio(file_path)\n",
        "    prediction = model.predict(preprocessed_audio)\n",
        "\n",
        "    predicted_class = classes[np.argmax(prediction)]\n",
        "    confidence = np.max(prediction) * 100  # Convert to percentage\n",
        "\n",
        "    print(f'Predicted Class: {predicted_class} ({confidence:.2f}%)')\n",
        "\n",
        "# Test on sample files\n",
        "test_audio_files = [\n",
        "\n",
        "    \"dog.wav\",\n",
        "    \"bird.wav\",\n",
        "    \"bird1.wav\",\n",
        "    \"frog.wav\",\n",
        "    \"rain.mp3\",\n",
        "    \"wind.mp3\",\n",
        "    \"cow.wav\"\n",
        "]\n",
        "\n",
        "for file in test_audio_files:\n",
        "    if os.path.exists(file):\n",
        "        print(f\"\\nTesting: {file}\")\n",
        "        predict_audio(file)\n",
        "    else:\n",
        "        print(f\"File not found: {file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3SL-qxFA58A",
        "outputId": "a88d8974-6150-40df-9dfc-969420cdfe3e"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing: dog.wav\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 200ms/step\n",
            "Predicted Class: dog (90.03%)\n",
            "\n",
            "Testing: bird.wav\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step\n",
            "Predicted Class: bird (93.51%)\n",
            "\n",
            "Testing: bird1.wav\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step\n",
            "Predicted Class: bird (96.84%)\n",
            "\n",
            "Testing: frog.wav\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step\n",
            "Predicted Class: frog (99.88%)\n",
            "\n",
            "Testing: rain.mp3\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step\n",
            "Predicted Class: others (99.73%)\n",
            "\n",
            "Testing: wind.mp3\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step\n",
            "Predicted Class: others (68.90%)\n",
            "\n",
            "Testing: cow.wav\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
            "Predicted Class: cow (99.51%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Get model predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)  # Convert softmax probabilities to class labels\n",
        "y_true_classes = np.argmax(y_test, axis=1)  # Convert one-hot encoding back to labels\n",
        "\n",
        "# Print classification report\n",
        "print(classification_report(y_true_classes, y_pred_classes, target_names=classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NZcU8wLCioo",
        "outputId": "265c0e52-9fc0-480a-c24c-bb55a0f845cc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 770ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         cat       0.94      0.88      0.91        34\n",
            "         dog       0.97      0.86      0.92        44\n",
            "        bird       0.98      1.00      0.99        45\n",
            "         cow       1.00      1.00      1.00        19\n",
            "        lion       0.89      1.00      0.94        17\n",
            "       sheep       0.87      1.00      0.93        13\n",
            "        frog       1.00      1.00      1.00        18\n",
            "     chicken       0.88      1.00      0.94        22\n",
            "      donkey       1.00      0.92      0.96        12\n",
            "      monkey       0.95      0.90      0.92        20\n",
            "      others       0.98      1.00      0.99        50\n",
            "\n",
            "    accuracy                           0.96       294\n",
            "   macro avg       0.95      0.96      0.95       294\n",
            "weighted avg       0.96      0.96      0.96       294\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Convert one-hot encoded y_test to class indices (integer labels)\n",
        "y_test_class = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Predict the class probabilities\n",
        "y_pred_proba = model.predict(X_test)\n",
        "\n",
        "# Get the class with the highest probability\n",
        "y_pred_class = np.argmax(y_pred_proba, axis=1)\n",
        "\n",
        "# Classify as \"others\" if the highest probability is less than 50%\n",
        "threshold = 0.5\n",
        "y_pred_class[y_pred_proba.max(axis=1) < threshold] = len(classes)  # \"others\" class\n",
        "\n",
        "# Evaluate the new predictions\n",
        "print(classification_report(y_test_class, y_pred_class))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y9Zhes5zMG_n",
        "outputId": "3f984252-75de-43cd-ef57-0c11aa68ace8"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 869ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.79      0.86        34\n",
            "           1       0.97      0.82      0.89        44\n",
            "           2       1.00      1.00      1.00        45\n",
            "           3       1.00      1.00      1.00        19\n",
            "           4       0.94      1.00      0.97        17\n",
            "           5       0.93      1.00      0.96        13\n",
            "           6       1.00      1.00      1.00        18\n",
            "           7       0.95      0.82      0.88        22\n",
            "           8       1.00      0.92      0.96        12\n",
            "           9       0.95      0.90      0.92        20\n",
            "          10       0.98      1.00      0.99        50\n",
            "          11       0.00      0.00      0.00         0\n",
            "\n",
            "    accuracy                           0.93       294\n",
            "   macro avg       0.89      0.85      0.87       294\n",
            "weighted avg       0.97      0.93      0.95       294\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    }
  ]
}